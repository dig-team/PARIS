/*
 *  Primitive Collections for Java.
 *  Copyright (C) 2002, 2003  S&oslash;ren Bak
 *
 *  This library is free software; you can redistribute it and/or
 *  modify it under the terms of the GNU Lesser General Public
 *  License as published by the Free Software Foundation; either
 *  version 2.1 of the License, or (at your option) any later version.
 *
 *  This library is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *  Lesser General Public License for more details.
 *
 *  You should have received a copy of the GNU Lesser General Public
 *  License along with this library; if not, write to the Free Software
 *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 */
package bak.pcj.benchmark;

import java.lang.reflect.Method;
import java.lang.reflect.Constructor;
import java.lang.reflect.Modifier;
import java.lang.reflect.InvocationTargetException;

import java.io.Writer;
import java.io.FileWriter;
import java.io.IOException;

/**
 *  Controls the execution of benchmarks. The runner automatically
 *  discovers benchmark tasks in benchmark classes using the 
 *  reflection mechanism. This procedure is inspired by the way that 
 *  JUnit works.
 *
 *  @author     S&oslash;ren Bak
 *  @version    1.1     2003/15/2
 *  @since      1.0
 */
public class BenchmarkRunner {

    /** Indicates whether verbose output should be enabled. */
    private boolean verbose = true;

    /** The report generated by this runner. */
    private Report report;

    /** The time used by the relax() method. */
    private long relaxTime = 4000L;

    /**
     *  Creates a new benchmark runner with an empty report.
     */
    public BenchmarkRunner() {
        report = new Report();
    }

    /**
     *  Enables or disables verbose output to <tt>System.out</tt>.
     *  Verbose output is enabled by default.
     *
     *  @param      verbose
     *              <tt>true</tt> if verbose output should be enabled;
     *              <tt>false</tt> otherwise.
     */
    public void setVerbose(boolean verbose)
    { this.verbose = verbose; }

    /**
     *  Relaxes the JVM by giving it a few seconds to garbage collect
     *  and stabilize disk I/O.
     */
    private void relax() {
        if (verbose)
            System.out.println("Garbage collecting...");
        System.gc();
        try {
            Thread.sleep(relaxTime);
        } catch (InterruptedException e) {
        }
    }

    private String nameOf(Class cls) {
        String name = cls.getName();
        int ldot = name.lastIndexOf('.');
        if (ldot != -1)
            name = name.substring(ldot+1);
        return name;
    }

    /**
     *  Returns the report produced by this benchmark runner.
     *  Note that the returned report is mutable and can be modified
     *  before formatting.
     *
     *  @return     the report produced by this benchmark runner.
     */
    public Report getReport()
    { return report; }

    /**
     *  Runs a specified benchmark on a specified data set.
     *  The results are collected in the runner's report.
     *
     *  @param      bm
     *              the benchmark to run.
     *
     *  @param      dataSet
     *              the data set on which to run the benchmark.
     *
     *  @see        #getReport()
     */
    public void runBenchmark(Benchmark bm, DataSet dataSet) {
        relax();

        //  Set up id's
        String classId = bm.getClassId();
        String dataSetId = dataSet.getId();
        String benchmarkId = nameOf(bm.getClass());
        String taskDescription = "";

        if (verbose)
            System.out.println("Running " + benchmarkId + "/" + classId + " with data " + dataSetId);

        //  Loop over benchmark methods
        Method[] methods = bm.getClass().getMethods();
        for (int i = 0; i < methods.length; i++) {
            Method m = methods[i];
            //  Non-abstract public methods that starts with "benchmark" and has one DataSet argument
            if ((m.getModifiers() & (Modifier.PUBLIC|Modifier.ABSTRACT)) == Modifier.PUBLIC && m.getName().startsWith("benchmark") && m.getParameterTypes().length == 1 && (DataSet.class).isAssignableFrom(m.getParameterTypes()[0]) ) {
                if (verbose)
                    System.out.println("  task: " + m.getName().substring("benchmark".length()));
                try {
                    taskDescription = (String)m.invoke(bm, new Object[]{dataSet});
                } catch (IllegalAccessException iae) {
                    throw new RuntimeException(iae.getMessage());
                } catch (InvocationTargetException ite) {
                    throw new RuntimeException(ite.getMessage());
                }
                long time = bm.readTimer();
                String taskId = m.getName().substring("benchmark".length());
                Result result = new Result(benchmarkId, dataSetId, classId, taskId, taskDescription, time);
                report.addResult(result);
            }
        }
    }

    private static void printUsageAndExit(Throwable e) {
        System.err.println("Usage: bak.pcj.benchmark.BenchmarkRunner <dataset class> <dataset size> <benchmark class> <output file>");
        if (e != null) {
            System.err.println("An exception was raised:");
            e.printStackTrace();
        }
        System.exit(1);
    }

    /**
     *  Runs the a benchmark from the command line.
     *  <br>The first parameter is the name of the data set class to use.
     *  <br>The second parameter is the size of the data sets to use.
     *  <br>The third parameter is the name of the benchmark class to use.
     *  <br>The fourth parameter is name of file on which to write the
     *  results.
     *
     *  @param      args
     *              as specified above.
     */
    public static void main(String[] args) {
        int size = 0;
        DataSet dataSet = null;
        Benchmark benchmark = null;
        Writer out = null;

        //  Check arguments
        if (args.length != 4)
            printUsageAndExit(null);

        //  Data set size
        try {
            size = Integer.parseInt(args[1]);
            if (size <= 0)
                printUsageAndExit(null);
        } catch (NumberFormatException e) {
            printUsageAndExit(e);
        }

        //  Data set
        try {
            Class dataSetClass = Class.forName(args[0]);
            Constructor c = dataSetClass.getConstructor(new Class[]{Integer.TYPE});
            dataSet = (DataSet)c.newInstance(new Object[]{new Integer(size)});
        } catch (InstantiationException ie) {
            printUsageAndExit(ie);
        } catch (IllegalAccessException iae) {
            printUsageAndExit(iae);
        } catch (ClassNotFoundException cnfe) {
            printUsageAndExit(cnfe);
        } catch (NoSuchMethodException nsme) {
            printUsageAndExit(nsme);
        } catch (InvocationTargetException ite) {
            printUsageAndExit(ite);
        }

        //  Benchmark
        try {
            Class benchmarkClass = Class.forName(args[2]);
            benchmark = (Benchmark)benchmarkClass.newInstance();
        } catch (InstantiationException ie) {
            printUsageAndExit(ie);
        } catch (IllegalAccessException iae) {
            printUsageAndExit(iae);
        } catch (ClassNotFoundException cnfe) {
            printUsageAndExit(cnfe);
        }

        //  Output
        try {
            out = new FileWriter(args[3]);
        } catch (IOException e) {
            printUsageAndExit(e);
        }

        BenchmarkRunner run = new BenchmarkRunner();

        //  Run once to load classes and compile code
        run.runBenchmark(benchmark, dataSet);
        run.report.clearResults();

        //  Run again to collect results
        run.runBenchmark(benchmark, dataSet);

        try {
            run.report.writeResults(out);
            out.flush();
            out.close();
        } catch (IOException e) {
            printUsageAndExit(e);
        }
    }

}
